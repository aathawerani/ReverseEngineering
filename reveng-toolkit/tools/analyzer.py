#!/usr/bin/env python3"""analyzer.pySimple static Java source analyzer that: - walks src tree, finds .java files - extracts package, class name, annotations (@RestController, @Service, @Repository, @Component, @FeignClient) - finds import lines to detect dependencies between classes/packages - creates a Structurizr DSL (workspace.dsl) in the output folderUsage:  python3 analyzer.py --src /path/to/project/src/main/java --out /path/to/output"""import os, re, sys, json, argparsefrom pathlib import Pathfrom collections import defaultdictdef find_java_files(src):    for root, dirs, files in os.walk(src):        for f in files:            if f.endswith(".java"):                yield os.path.join(root, f)pkg_re = re.compile(r'^\s*package\s+([a-zA-Z0-9_.]+)\s*;')class_re = re.compile(r'^\s*(public\s+)?(class|interface|enum)\s+([A-Za-z0-9_]+)')import_re = re.compile(r'^\s*import\s+([a-zA-Z0-9_.]+)')ann_re = re.compile(r'@\s*(RestController|Controller|Service|Repository|Component|FeignClient)', re.IGNORECASE)def parse_file(path):    pkg = None    classname = None    anns = set()    imports = set()    try:        with open(path, 'r', encoding='utf-8', errors='ignore') as fh:            for line in fh:                if pkg is None:                    m = pkg_re.match(line)                    if m:                        pkg = m.group(1)                if classname is None:                    m = class_re.match(line)                    if m:                        classname = m.group(3)                m = import_re.match(line)                if m:                    imports.add(m.group(1))                for a in ann_re.findall(line):                    anns.add(a)    except Exception as e:        # skip files that can't be read        return None    if pkg is None:        pkg = "default"    if classname is None:        # fallback to filename        classname = Path(path).stem    return {        "path": path,        "package": pkg,        "class": classname,        "annotations": list(anns),        "imports": list(imports)    }def top_pkg(pkg, depth=2):    parts = pkg.split(".")    return ".".join(parts[:depth]) if len(parts)>=depth else pkgdef build_model(parsed_files, package_depth=2):    # containers are top-level packages    containers = defaultdict(list)   # container -> list of class ids    components = {}  # id -> dict    # map full class name to simple id    classname_by_fqn = {}    for p in parsed_files:        fqn = p["package"] + "." + p["class"]        classname_by_fqn[fqn] = p    # build containers and components    for p in parsed_files:        cont = top_pkg(p["package"], package_depth)        containers[cont].append(p["package"] + "." + p["class"])        role = "Component"        for a in p["annotations"]:            if a.lower() in ("restcontroller","controller"):                role = "Controller"                break            if a.lower()=="service":                role = "Service"                break            if a.lower()=="repository":                role = "Repository"                break            if a.lower()=="feignclient":                role = "External"  # feign clients -> external dependencies                break        components[p["package"] + "." + p["class"]] = {            "name": p["class"],            "fqn": p["package"] + "." + p["class"],            "package": p["package"],            "container": cont,            "role": role,            "imports": p["imports"]        }    # dependencies between components using imports    relations = []    for fqn, comp in components.items():        for imp in comp["imports"]:            # find if import corresponds to a class we parsed            # use startswith match to map package dependency to a known fqn            for target_fqn, target in components.items():                if imp.startswith(target["package"]):                    relations.append( (fqn, target_fqn) )    return containers, components, relationsdef write_structurizr_dsl(output_dir, containers, components, relations):    out = []    out.append('workspace "Auto-extracted Workspace" "Generated by static analyzer" {')    out.append('  model {')    out.append('    user = person "End User" "A user of the system"')    out.append('')    # create software system to hold containers    out.append('    system = softwareSystem "Application" "Auto-extracted system"')    out.append('    user -> system "Uses"')    out.append('')    # create containers    for cont_name in containers.keys():        out.append(f'    {cont_name.replace(".","_")} = system.addContainer("{cont_name}", "Auto-detected package container", "Java")')    out.append('')    # create components inside containers    for comp_fqn, comp in components.items():        cont_var = comp["container"].replace(".","_")        # sanitize names        cname = comp["name"].replace('"','')        out.append(f'    {comp_fqn.replace(".","_")} = {cont_var}.addComponent("{cname}", "{comp["role"]}", "Java")')    out.append('')    # add relationships (simple)    for a,b in relations:        a_var = a.replace(".","_")        b_var = b.replace(".","_")        out.append(f'    {a_var}.uses({b_var}, "uses")')    out.append('  }')    out.append('  views {')    out.append('    systemContext system { include *; autolayout lr; title "System Context" }')    out.append('    container system { include *; autolayout lr; title "Container Diagram" }')    # create a component view for each container    for cont in containers.keys():        cont_var = cont.replace(".","_")        out.append(f'    component {cont_var} {{ include *; autolayout lr; title "Components in {cont}" }}')    out.append('    theme default')    out.append('  }')    out.append('}')    dsl = "\n".join(out)    with open(os.path.join(output_dir, "workspace.dsl"), "w", encoding="utf-8") as fh:        fh.write(dsl)    # also write a simple JSON summary    summary = {        "containers": {k: v for k,v in containers.items()},        "components": components,        "relations": relations    }    with open(os.path.join(output_dir, "summary.json"), "w", encoding="utf-8") as fh:        json.dump(summary, fh, indent=2)    print("Wrote:", os.path.join(output_dir, "workspace.dsl"))    print("Wrote:", os.path.join(output_dir, "summary.json"))def main():    parser = argparse.ArgumentParser()    parser.add_argument("--src", required=True, help="path to java sources (root folder)")    parser.add_argument("--out", required=True, help="output folder for workspace.dsl and artifacts")    parser.add_argument("--pkg-depth", type=int, default=2, help="package depth for container grouping")    args = parser.parse_args()    src = args.src    out = args.out    depth = args.pkg_depth    if not os.path.isdir(src):        print("Source path not found:", src)        sys.exit(2)    os.makedirs(out, exist_ok=True)    files = list(find_java_files(src))    print("Found .java files:", len(files))    parsed = []    for f in files:        p = parse_file(f)        if p:            parsed.append(p)    print("Parsed files:", len(parsed))    containers, components, relations = build_model(parsed, package_depth=depth)    write_structurizr_dsl(out, containers, components, relations)if __name__ == "__main__":    main()